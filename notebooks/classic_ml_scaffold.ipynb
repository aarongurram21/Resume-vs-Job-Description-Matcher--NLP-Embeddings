{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eba606f",
   "metadata": {},
   "source": [
    "# Project Structure Setup\n",
    "Create a classic ML skeleton with standard directories and placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "folders = [\n",
    "    \"data/raw\",\n",
    "    \"data/processed\",\n",
    "    \"models\",\n",
    "    \"reports/figures\",\n",
    "    \"src\",\n",
    "    \"tests\",\n",
    "    \"configs\",\n",
    "    \"scripts\",\n",
    "    \"notebooks\",\n",
    "    \".vscode\",\n",
    "]\n",
    "for folder in folders:\n",
    "    path = PROJECT_ROOT / folder\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"created {path}\")\n",
    "\n",
    "# placeholder files\n",
    "for keep in [\"data/raw/.gitkeep\", \"data/processed/.gitkeep\", \"models/.gitkeep\", \"reports/.gitkeep\"]:\n",
    "    keep_path = PROJECT_ROOT / keep\n",
    "    keep_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    keep_path.touch(exist_ok=True)\n",
    "    print(f\"touched {keep_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6b608",
   "metadata": {},
   "source": [
    "# Create requirements.txt\n",
    "Write common ML dependencies to requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"\\\n",
    "numpy\n",
    "pandas\n",
    "scikit-learn\n",
    "matplotlib\n",
    "seaborn\n",
    "pyyaml\n",
    "joblib\n",
    "click\n",
    "\"\"\"\n",
    "req_path = PROJECT_ROOT / \"requirements.txt\"\n",
    "req_path.write_text(requirements.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "print(f\"wrote {req_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703161e",
   "metadata": {},
   "source": [
    "# Data Directory and Sample Dataset\n",
    "Generate a toy dataset and store raw/processed splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd624ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_df = pd.DataFrame(\n",
    "    {\n",
    "        \"feature1\": np.random.randn(200),\n",
    "        \"feature2\": np.random.rand(200) * 10,\n",
    "        \"target\": np.random.randint(0, 2, size=200),\n",
    "    }\n",
    ")\n",
    "raw_path = PROJECT_ROOT / \"data/raw/sample.csv\"\n",
    "raw_df.to_csv(raw_path, index=False)\n",
    "print(f\"wrote raw sample to {raw_path}\")\n",
    "\n",
    "# simple train/val split\n",
    "train_df = raw_df.sample(frac=0.8, random_state=42)\n",
    "val_df = raw_df.drop(train_df.index)\n",
    "train_path = PROJECT_ROOT / \"data/processed/train.csv\"\n",
    "val_path = PROJECT_ROOT / \"data/processed/val.csv\"\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "print(f\"processed splits saved to {train_path} and {val_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e584ea",
   "metadata": {},
   "source": [
    "# Source Package Initialization\n",
    "Create src/ package and ensure __init__.py exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_init = PROJECT_ROOT / \"src/__init__.py\"\n",
    "src_init.parent.mkdir(parents=True, exist_ok=True)\n",
    "src_init.touch(exist_ok=True)\n",
    "print(f\"ensured package at {src_init}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b77b3a3",
   "metadata": {},
   "source": [
    "# Data Loading Module (`src/data/load_data.py`)\n",
    "Implement helpers to read raw CSVs and write cleaned splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6885278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = PROJECT_ROOT / \"src/data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "load_data_py = data_dir / \"load_data.py\"\n",
    "load_data_py.write_text(\n",
    "    \"\"\"\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = Path(__file__).resolve().parents[2] / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = Path(__file__).resolve().parents[2] / \"data\" / \"processed\"\n",
    "\n",
    "\n",
    "def load_raw(name: str) -> pd.DataFrame:\n",
    "    path = RAW_DIR / name\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def save_processed(train: pd.DataFrame, val: pd.DataFrame, train_name: str = \"train.csv\", val_name: str = \"val.csv\") -> Tuple[Path, Path]:\n",
    "    PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    train_path = PROCESSED_DIR / train_name\n",
    "    val_path = PROCESSED_DIR / val_name\n",
    "    train.to_csv(train_path, index=False)\n",
    "    val.to_csv(val_path, index=False)\n",
    "    return train_path, val_path\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {load_data_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa66f86",
   "metadata": {},
   "source": [
    "# Feature Engineering Module (`src/features/build_features.py`)\n",
    "Add basic preprocessing and pipeline builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = PROJECT_ROOT / \"src/features\"\n",
    "features_dir.mkdir(parents=True, exist_ok=True)\n",
    "build_features_py = features_dir / \"build_features.py\"\n",
    "build_features_py.write_text(\n",
    "    \"\"\"\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "NUMERIC = [\"feature1\", \"feature2\"]\n",
    "\n",
    "\n",
    "def build_preprocessor(numeric_features: List[str] = None) -> ColumnTransformer:\n",
    "    numeric_features = numeric_features or NUMERIC\n",
    "    numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[(\"num\", numeric_transformer, numeric_features)], remainder=\"drop\"\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def separate_features_targets(df: pd.DataFrame, target_col: str = \"target\"):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X, y\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {build_features_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90cd53",
   "metadata": {},
   "source": [
    "# Model Definition (`src/models/model.py`)\n",
    "Provide a simple model factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41097ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = PROJECT_ROOT / \"src/models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_py = models_dir / \"model.py\"\n",
    "model_py.write_text(\n",
    "    \"\"\"\n",
    "from typing import Literal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "ModelName = Literal[\"logreg\", \"rf\"]\n",
    "\n",
    "\n",
    "def make_model(name: ModelName = \"logreg\"):\n",
    "    if name == \"rf\":\n",
    "        return RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    return LogisticRegression(max_iter=500)\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {model_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7547eb",
   "metadata": {},
   "source": [
    "# Training Script (`src/train.py`)\n",
    "Train a model, persist it, and log metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py = PROJECT_ROOT / \"src/train.py\"\n",
    "train_py.write_text(\n",
    "    \"\"\"\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from src.data.load_data import load_raw, save_processed\n",
    "from src.features.build_features import build_preprocessor, separate_features_targets\n",
    "from src.models.model import make_model\n",
    "\n",
    "\n",
    "def train(raw_name: str = \"sample.csv\", model_name: str = \"logreg\", model_dir: Path = Path(\"models\")) -> dict:\n",
    "    df = load_raw(raw_name)\n",
    "    train_df = df.sample(frac=0.8, random_state=42)\n",
    "    val_df = df.drop(train_df.index)\n",
    "    save_processed(train_df, val_df)\n",
    "\n",
    "    X_train, y_train = separate_features_targets(train_df)\n",
    "    X_val, y_val = separate_features_targets(val_df)\n",
    "\n",
    "    preprocessor = build_preprocessor()\n",
    "    model = make_model(model_name)\n",
    "    clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_val, y_pred)),\n",
    "        \"f1\": float(f1_score(y_val, y_pred)),\n",
    "    }\n",
    "\n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    artifact = model_dir / f\"model_{model_name}.joblib\"\n",
    "    joblib.dump(clf, artifact)\n",
    "    return {\"metrics\": metrics, \"artifact\": artifact}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = train()\n",
    "    print(result)\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {train_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d89bc",
   "metadata": {},
   "source": [
    "# Evaluation Script (`src/evaluate.py`)\n",
    "Load the saved model, score on validation data, and save reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b714403",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_py = PROJECT_ROOT / \"src/evaluate.py\"\n",
    "evaluate_py.write_text(\n",
    "    \"\"\"\n",
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "from src.data.load_data import load_raw, save_processed\n",
    "from src.features.build_features import separate_features_targets\n",
    "\n",
    "\n",
    "def evaluate(raw_name: str = \"sample.csv\", model_path: Path = Path(\"models/model_logreg.joblib\"), report_dir: Path = Path(\"reports\")) -> dict:\n",
    "    df = load_raw(raw_name)\n",
    "    train_df = df.sample(frac=0.8, random_state=42)\n",
    "    val_df = df.drop(train_df.index)\n",
    "    save_processed(train_df, val_df)\n",
    "\n",
    "    _, y_train = separate_features_targets(train_df)\n",
    "    X_val, y_val = separate_features_targets(val_df)\n",
    "\n",
    "    clf = joblib.load(model_path)\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_val, y_pred)),\n",
    "        \"f1\": float(f1_score(y_val, y_pred)),\n",
    "    }\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "    report_dir = Path(report_dir)\n",
    "    report_dir.mkdir(parents=True, exist_ok=True)\n",
    "    report_path = report_dir / \"classification_report.json\"\n",
    "    with report_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "\n",
    "    return {\"metrics\": metrics, \"report_path\": report_path}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = evaluate()\n",
    "    print(result)\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {evaluate_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad891e7",
   "metadata": {},
   "source": [
    "# Configuration File (`config.yaml`)\n",
    "Create a YAML config for paths and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2388044",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = PROJECT_ROOT / \"configs/config.yaml\"\n",
    "config_path.write_text(\n",
    "    \"\"\"\n",
    "paths:\n",
    "  raw_data: data/raw\n",
    "  processed_data: data/processed\n",
    "  models: models\n",
    "  reports: reports\n",
    "model:\n",
    "  name: logreg\n",
    "  random_state: 42\n",
    "train:\n",
    "  test_size: 0.2\n",
    "  random_state: 42\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {config_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e6de6",
   "metadata": {},
   "source": [
    "# Unit Tests (`tests/`)\n",
    "Add pytest stubs for data loading and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dir = PROJECT_ROOT / \"tests\"\n",
    "tests_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(tests_dir / \"test_data.py\").write_text(\n",
    "    \"\"\"\n",
    "from src.data.load_data import load_raw\n",
    "\n",
    "def test_load_raw_smoke():\n",
    "    df = load_raw(\"sample.csv\")\n",
    "    assert not df.empty\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "(tests_dir / \"test_model.py\").write_text(\n",
    "    \"\"\"\n",
    "from src.train import train\n",
    "\n",
    "def test_train_returns_metrics(tmp_path):\n",
    "    result = train(model_dir=tmp_path)\n",
    "    assert \"metrics\" in result\n",
    "    assert result[\"artifact\"].exists()\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\"wrote test stubs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0d521",
   "metadata": {},
   "source": [
    "# CLI Entrypoint (`main.py`)\n",
    "Expose prep/train/eval commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72cb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_py = PROJECT_ROOT / \"main.py\"\n",
    "main_py.write_text(\n",
    "    \"\"\"\n",
    "import click\n",
    "from src.train import train\n",
    "from src.evaluate import evaluate\n",
    "\n",
    "\n",
    "@click.group()\n",
    "def cli():\n",
    "    \"\"\"CLI for classic ML pipeline.\"\"\"\n",
    "\n",
    "\n",
    "@cli.command()\n",
    "@click.option(\"--raw-name\", default=\"sample.csv\")\n",
    "@click.option(\"--model-name\", default=\"logreg\")\n",
    "def train_cmd(raw_name: str, model_name: str):\n",
    "    result = train(raw_name=raw_name, model_name=model_name)\n",
    "    click.echo(result)\n",
    "\n",
    "\n",
    "@cli.command()\n",
    "@click.option(\"--raw-name\", default=\"sample.csv\")\n",
    "@click.option(\"--model-path\", default=\"models/model_logreg.joblib\")\n",
    "def evaluate_cmd(raw_name: str, model_path: str):\n",
    "    result = evaluate(raw_name=raw_name, model_path=model_path)\n",
    "    click.echo(result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cli()\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {main_py}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99ea3d",
   "metadata": {},
   "source": [
    "# Makefile Tasks\n",
    "Add common automation targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d07c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "makefile_path = PROJECT_ROOT / \"Makefile\"\n",
    "makefile_path.write_text(\n",
    "    \"\"\"\n",
    "install:\n",
    "\\tpip install -r requirements.txt\n",
    "\n",
    "lint:\n",
    "\\tpython -m compileall src\n",
    "\n",
    "test:\n",
    "\\tpytest -q\n",
    "\n",
    "train:\n",
    "\\tpython main.py train-cmd\n",
    "\n",
    "evaluate:\n",
    "\\tpython main.py evaluate-cmd\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"wrote {makefile_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a1ea3",
   "metadata": {},
   "source": [
    "# VS Code Tasks and Launch Configurations\n",
    "Generate tasks and launch configs for tests and scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "vscode_dir = PROJECT_ROOT / \".vscode\"\n",
    "vscode_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tasks = {\n",
    "    \"version\": \"2.0.0\",\n",
    "    \"tasks\": [\n",
    "        {\n",
    "            \"label\": \"pytest\",\n",
    "            \"type\": \"shell\",\n",
    "            \"command\": \"pytest\",\n",
    "            \"group\": \"test\",\n",
    "            \"problemMatcher\": \"$pytest\",\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"train\",\n",
    "            \"type\": \"shell\",\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"main.py\", \"train-cmd\"],\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"evaluate\",\n",
    "            \"type\": \"shell\",\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"main.py\", \"evaluate-cmd\"],\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "(vscode_dir / \"tasks.json\").write_text(json.dumps(tasks, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "launch = {\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Python: Train\",\n",
    "            \"type\": \"python\",\n",
    "            \"request\": \"launch\",\n",
    "            \"program\": \"${workspaceFolder}/main.py\",\n",
    "            \"args\": [\"train-cmd\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Python: Evaluate\",\n",
    "            \"type\": \"python\",\n",
    "            \"request\": \"launch\",\n",
    "            \"program\": \"${workspaceFolder}/main.py\",\n",
    "            \"args\": [\"evaluate-cmd\"],\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "(vscode_dir / \"launch.json\").write_text(json.dumps(launch, indent=2), encoding=\"utf-8\")\n",
    "print(\"wrote .vscode/tasks.json and launch.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadda08a",
   "metadata": {},
   "source": [
    "# Dockerfile and `.dockerignore`\n",
    "Containerize the project and trim build context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile_path = PROJECT_ROOT / \"Dockerfile\"\n",
    "dockerfile_path.write_text(\n",
    "    \"\"\"\n",
    "FROM python:3.10-slim\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"python\", \"main.py\", \"train-cmd\"]\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "\n",
    "ignore_path = PROJECT_ROOT / \".dockerignore\"\n",
    "ignore_path.write_text(\n",
    "    \"\"\"\n",
    "__pycache__\n",
    "*.pyc\n",
    ".env\n",
    ".vscode\n",
    ".venv\n",
    ".data\n",
    "reports\n",
    "models\n",
    "\"\"\".strip()\n",
    "    + \"\\n\",\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\"wrote Dockerfile and .dockerignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a3dce",
   "metadata": {},
   "source": [
    "# Run End-to-End Pipeline from Notebook\n",
    "Call the CLI commands to train and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd63744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "print(\"running training via CLI...\")\n",
    "subprocess.run([sys.executable, \"main.py\", \"train-cmd\"], cwd=PROJECT_ROOT)\n",
    "print(\"running evaluation via CLI...\")\n",
    "subprocess.run([sys.executable, \"main.py\", \"evaluate-cmd\"], cwd=PROJECT_ROOT)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
